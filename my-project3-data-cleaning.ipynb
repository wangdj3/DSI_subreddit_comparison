{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "600347c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDIT ME to change target subreddit...\n",
    "target_subreddit = \"comicbooks\" # scraped data includes: ['Naruto', 'BokuNoHeroAcademia', 'anime', 'manga', 'comicbooks',\n",
    "                                                    # 'StarWars', 'startrek', 'LonghornNation', 'cfb', 'Genshin_Impact']\n",
    "scrape_type = \"submission\"  # set to \"submission\" or \"comment\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb46bc9f",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "857cad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "# from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77507a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "all_data = pd.read_csv(f'./data/{target_subreddit}_{scrape_type}s.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26f15412",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>gilded</th>\n",
       "      <th>is_gallery</th>\n",
       "      <th>title</th>\n",
       "      <th>link_flair_richtext</th>\n",
       "      <th>subreddit_name_prefixed</th>\n",
       "      <th>hidden</th>\n",
       "      <th>...</th>\n",
       "      <th>retrieved_utc</th>\n",
       "      <th>updated_utc</th>\n",
       "      <th>utc_datetime_str</th>\n",
       "      <th>post_hint</th>\n",
       "      <th>crosspost_parent_list</th>\n",
       "      <th>preview</th>\n",
       "      <th>link_flair_template_id</th>\n",
       "      <th>crosspost_parent</th>\n",
       "      <th>author_cakeday</th>\n",
       "      <th>edited_on</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>comicbooks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_a0obk3gv</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Planet Hulk body used to create The Maxx</td>\n",
       "      <td>[]</td>\n",
       "      <td>r/comicbooks</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1677990867</td>\n",
       "      <td>1677990868</td>\n",
       "      <td>2023-03-05 04:34:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>comicbooks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_112uoc</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[OC] Frontier Graveyard has a new episode.</td>\n",
       "      <td>[{'e': 'text', 't': 'News'}]</td>\n",
       "      <td>r/comicbooks</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1677990594</td>\n",
       "      <td>1677990594</td>\n",
       "      <td>2023-03-05 04:29:42</td>\n",
       "      <td>image</td>\n",
       "      <td>[{'approved_at_utc': None, 'subreddit': 'zombi...</td>\n",
       "      <td>{'images': [{'source': {'url': 'https://previe...</td>\n",
       "      <td>e00f666e-4b9c-11e3-8795-12313b074434</td>\n",
       "      <td>t3_11ilf8q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>comicbooks</td>\n",
       "      <td>Starting my second box and would prefer not ge...</td>\n",
       "      <td>t2_68d44nnp</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Any recommendations on quality storage boxes?</td>\n",
       "      <td>[{'e': 'text', 't': 'Question'}]</td>\n",
       "      <td>r/comicbooks</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1677990059</td>\n",
       "      <td>1677990060</td>\n",
       "      <td>2023-03-05 04:20:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>313e6c50-bc89-11e1-ae6a-12313d14a568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>comicbooks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_j0ubh1u</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Favorite comic book cameos from characters out...</td>\n",
       "      <td>[{'e': 'text', 't': 'Excerpt'}]</td>\n",
       "      <td>r/comicbooks</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1677984267</td>\n",
       "      <td>1677984267</td>\n",
       "      <td>2023-03-05 02:44:13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0583ca00-b4a1-11e1-ae43-12313b0c247a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>comicbooks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_75sge4r3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Got these Two off of Amazon today</td>\n",
       "      <td>[{'e': 'text', 't': 'Other'}]</td>\n",
       "      <td>r/comicbooks</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1677983783</td>\n",
       "      <td>1677983784</td>\n",
       "      <td>2023-03-05 02:36:11</td>\n",
       "      <td>image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'images': [{'source': {'url': 'https://previe...</td>\n",
       "      <td>cbfa3ab2-4bc1-11e3-9fcd-12313b04ceaf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   subreddit                                           selftext  \\\n",
       "0           0  comicbooks                                                NaN   \n",
       "1           1  comicbooks                                                NaN   \n",
       "2           2  comicbooks  Starting my second box and would prefer not ge...   \n",
       "3           3  comicbooks                                                NaN   \n",
       "4           4  comicbooks                                                NaN   \n",
       "\n",
       "  author_fullname  gilded is_gallery  \\\n",
       "0     t2_a0obk3gv       0       True   \n",
       "1       t2_112uoc       0        NaN   \n",
       "2     t2_68d44nnp       0        NaN   \n",
       "3      t2_j0ubh1u       0       True   \n",
       "4     t2_75sge4r3       0        NaN   \n",
       "\n",
       "                                               title  \\\n",
       "0           Planet Hulk body used to create The Maxx   \n",
       "1         [OC] Frontier Graveyard has a new episode.   \n",
       "2      Any recommendations on quality storage boxes?   \n",
       "3  Favorite comic book cameos from characters out...   \n",
       "4                  Got these Two off of Amazon today   \n",
       "\n",
       "                link_flair_richtext subreddit_name_prefixed  hidden  ...  \\\n",
       "0                                []            r/comicbooks   False  ...   \n",
       "1      [{'e': 'text', 't': 'News'}]            r/comicbooks   False  ...   \n",
       "2  [{'e': 'text', 't': 'Question'}]            r/comicbooks   False  ...   \n",
       "3   [{'e': 'text', 't': 'Excerpt'}]            r/comicbooks   False  ...   \n",
       "4     [{'e': 'text', 't': 'Other'}]            r/comicbooks   False  ...   \n",
       "\n",
       "   retrieved_utc updated_utc     utc_datetime_str  post_hint  \\\n",
       "0     1677990867  1677990868  2023-03-05 04:34:10        NaN   \n",
       "1     1677990594  1677990594  2023-03-05 04:29:42      image   \n",
       "2     1677990059  1677990060  2023-03-05 04:20:47        NaN   \n",
       "3     1677984267  1677984267  2023-03-05 02:44:13        NaN   \n",
       "4     1677983783  1677983784  2023-03-05 02:36:11      image   \n",
       "\n",
       "                               crosspost_parent_list  \\\n",
       "0                                                NaN   \n",
       "1  [{'approved_at_utc': None, 'subreddit': 'zombi...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                             preview  \\\n",
       "0                                                NaN   \n",
       "1  {'images': [{'source': {'url': 'https://previe...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  {'images': [{'source': {'url': 'https://previe...   \n",
       "\n",
       "                 link_flair_template_id crosspost_parent  author_cakeday  \\\n",
       "0                                   NaN              NaN             NaN   \n",
       "1  e00f666e-4b9c-11e3-8795-12313b074434       t3_11ilf8q             NaN   \n",
       "2  313e6c50-bc89-11e1-ae6a-12313d14a568              NaN             NaN   \n",
       "3  0583ca00-b4a1-11e1-ae43-12313b0c247a              NaN             NaN   \n",
       "4  cbfa3ab2-4bc1-11e3-9fcd-12313b04ceaf              NaN             NaN   \n",
       "\n",
       "   edited_on  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb98f97",
   "metadata": {},
   "source": [
    "# Choosing a sub-set of columns worth keeping for (possible) analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "573b3f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'subreddit', 'selftext', 'author_fullname', 'gilded',\n",
       "       'is_gallery', 'title', 'link_flair_richtext', 'subreddit_name_prefixed',\n",
       "       'hidden', 'pwls', 'link_flair_css_class', 'thumbnail_height',\n",
       "       'top_awarded_type', 'hide_score', 'media_metadata', 'quarantine',\n",
       "       'link_flair_text_color', 'upvote_ratio',\n",
       "       'author_flair_background_color', 'domain', 'media_embed',\n",
       "       'thumbnail_width', 'author_flair_template_id', 'is_original_content',\n",
       "       'secure_media', 'is_reddit_media_domain', 'is_meta', 'category',\n",
       "       'secure_media_embed', 'gallery_data', 'link_flair_text', 'score',\n",
       "       'is_created_from_ads_ui', 'author_premium', 'thumbnail', 'edited',\n",
       "       'author_flair_css_class', 'author_flair_richtext', 'gildings',\n",
       "       'content_categories', 'is_self', 'subreddit_type', 'link_flair_type',\n",
       "       'wls', 'removed_by_category', 'author_flair_type',\n",
       "       'total_awards_received', 'allow_live_comments', 'suggested_sort',\n",
       "       'url_overridden_by_dest', 'view_count', 'archived', 'no_follow',\n",
       "       'is_crosspostable', 'pinned', 'over_18', 'all_awardings', 'awarders',\n",
       "       'media_only', 'can_gild', 'spoiler', 'locked', 'author_flair_text',\n",
       "       'treatment_tags', 'removed_by', 'distinguished', 'subreddit_id',\n",
       "       'link_flair_background_color', 'id', 'is_robot_indexable', 'author',\n",
       "       'discussion_type', 'num_comments', 'send_replies', 'whitelist_status',\n",
       "       'contest_mode', 'author_patreon_flair', 'author_flair_text_color',\n",
       "       'permalink', 'parent_whitelist_status', 'stickied', 'url',\n",
       "       'subreddit_subscribers', 'created_utc', 'num_crossposts', 'media',\n",
       "       'is_video', 'retrieved_utc', 'updated_utc', 'utc_datetime_str',\n",
       "       'post_hint', 'crosspost_parent_list', 'preview',\n",
       "       'link_flair_template_id', 'crosspost_parent', 'author_cakeday',\n",
       "       'edited_on'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46e4a1c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# columns investigated one-by-one, systematically... no real valuable data found other than columns used below\n",
    "\n",
    "# all_data['gildings'].value_counts()\n",
    "# all_data[all_data['gildings']!=\"{}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30827aef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>title</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>is_reddit_media_domain</th>\n",
       "      <th>domain</th>\n",
       "      <th>over_18</th>\n",
       "      <th>spoiler</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>is_video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comicbooks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_a0obk3gv</td>\n",
       "      <td>Planet Hulk body used to create The Maxx</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>11inl15</td>\n",
       "      <td>Hairy-Ad9897</td>\n",
       "      <td>0</td>\n",
       "      <td>1677990850</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comicbooks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_112uoc</td>\n",
       "      <td>[OC] Frontier Graveyard has a new episode.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>11inhqq</td>\n",
       "      <td>profesone</td>\n",
       "      <td>0</td>\n",
       "      <td>1677990582</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comicbooks</td>\n",
       "      <td>Starting my second box and would prefer not ge...</td>\n",
       "      <td>t2_68d44nnp</td>\n",
       "      <td>Any recommendations on quality storage boxes?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>self.comicbooks</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>11inb9l</td>\n",
       "      <td>HenjaminBenry</td>\n",
       "      <td>0</td>\n",
       "      <td>1677990047</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comicbooks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_j0ubh1u</td>\n",
       "      <td>Favorite comic book cameos from characters out...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>11ilad6</td>\n",
       "      <td>Christianduty</td>\n",
       "      <td>0</td>\n",
       "      <td>1677984253</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comicbooks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_75sge4r3</td>\n",
       "      <td>Got these Two off of Amazon today</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>11il46k</td>\n",
       "      <td>NinjaZero2099</td>\n",
       "      <td>0</td>\n",
       "      <td>1677983771</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit                                           selftext  \\\n",
       "0  comicbooks                                                NaN   \n",
       "1  comicbooks                                                NaN   \n",
       "2  comicbooks  Starting my second box and would prefer not ge...   \n",
       "3  comicbooks                                                NaN   \n",
       "4  comicbooks                                                NaN   \n",
       "\n",
       "  author_fullname                                              title  \\\n",
       "0     t2_a0obk3gv           Planet Hulk body used to create The Maxx   \n",
       "1       t2_112uoc         [OC] Frontier Graveyard has a new episode.   \n",
       "2     t2_68d44nnp      Any recommendations on quality storage boxes?   \n",
       "3      t2_j0ubh1u  Favorite comic book cameos from characters out...   \n",
       "4     t2_75sge4r3                  Got these Two off of Amazon today   \n",
       "\n",
       "   upvote_ratio  is_reddit_media_domain           domain  over_18  spoiler  \\\n",
       "0           1.0                   False       reddit.com    False    False   \n",
       "1           1.0                    True        i.redd.it    False    False   \n",
       "2           1.0                   False  self.comicbooks    False    False   \n",
       "3           1.0                   False       reddit.com    False    False   \n",
       "4           1.0                    True        i.redd.it    False    False   \n",
       "\n",
       "        id         author  num_comments  created_utc  is_video  \n",
       "0  11inl15   Hairy-Ad9897             0   1677990850     False  \n",
       "1  11inhqq      profesone             0   1677990582     False  \n",
       "2  11inb9l  HenjaminBenry             0   1677990047     False  \n",
       "3  11ilad6  Christianduty             0   1677984253     False  \n",
       "4  11il46k  NinjaZero2099             0   1677983771     False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = all_data[['subreddit','selftext', 'author_fullname', 'title', 'upvote_ratio', \n",
    "              'is_reddit_media_domain', 'domain', 'over_18', 'spoiler', 'id', \n",
    "              'author', 'num_comments', 'created_utc', 'is_video'\n",
    "             ]].copy()   #used .copy() to reduce number of warnings later\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a12075",
   "metadata": {},
   "source": [
    "# Create new columns that might be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a93b8f8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert UTC times to human-readable\n",
    "\n",
    "df['created_datetime'] = pd.to_datetime(df['created_utc'], unit='s')\n",
    "\n",
    "#Reference: https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68642b79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a combined column of seltext + title, for combined processing\n",
    "\n",
    "cond1 = df['selftext'].notna()\n",
    "cond2 = df['selftext'] != '[removed]'\n",
    "\n",
    "df['combined_text'] = np.where((cond1 & cond2),\n",
    "                                df['title'] + \" \" + df['selftext'],\n",
    "                                df['title'])      #if selftext is blank or [removed], just use only the title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d967ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"combined_text_length\"] = df['combined_text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f6e433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"combined_wordcount\"] = df['combined_text'].str.split(\" \").str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22bb24f",
   "metadata": {},
   "source": [
    "# Text normalization (lemmatizing, tokenizing, stop words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3de16b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panda\\AppData\\Local\\Temp\\ipykernel_22172\\3621847600.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lemmatized_text'][i] = \\\n"
     ]
    }
   ],
   "source": [
    "# Lemmatizing \n",
    "# Reference: Lesson 504\n",
    "\n",
    "wn = WordNetLemmatizer()\n",
    "\n",
    "def custom_lemmatize(word, tag):\n",
    "    mapper = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'V': wordnet.VERB,\n",
    "        'N': wordnet.NOUN,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "    pos = mapper.get(tag[0])\n",
    "    \n",
    "    return wn.lemmatize(word, pos) if pos else word\n",
    "\n",
    "df['lemmatized_text'] = \"\"\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    df['lemmatized_text'][i] = \\\n",
    "        \" \".join([custom_lemmatize(word, tag) for word, tag in nltk.pos_tag( df['combined_text'][i].split(\" \"))])\n",
    "    \n",
    "    #Runs slow & gives a warning, but works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "550da503",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panda\\AppData\\Local\\Temp\\ipykernel_22172\\3578492394.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tokenized_text'][i] = recombined_text\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing & stopword removal AFTER lemmatizing\n",
    "# Reference: Lesson 504\n",
    "\n",
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "\n",
    "df['tokenized_text'] = \"\"\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    my_text_tokens = tokenizer.tokenize(df['lemmatized_text'][i].lower())\n",
    "    my_text_tokens_ns = [token for token in my_text_tokens if token not in stopwords.words(\"english\")]\n",
    "    recombined_text = \" \".join(my_text_tokens_ns)\n",
    "    df['tokenized_text'][i] = recombined_text\n",
    "    \n",
    "    #Runs slow & gives a warning, but works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd37cedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>title</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>is_reddit_media_domain</th>\n",
       "      <th>domain</th>\n",
       "      <th>over_18</th>\n",
       "      <th>spoiler</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>is_video</th>\n",
       "      <th>created_datetime</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>combined_text_length</th>\n",
       "      <th>combined_wordcount</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comicbooks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_a0obk3gv</td>\n",
       "      <td>Planet Hulk body used to create The Maxx</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>11inl15</td>\n",
       "      <td>Hairy-Ad9897</td>\n",
       "      <td>0</td>\n",
       "      <td>1677990850</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-03-05 04:34:10</td>\n",
       "      <td>Planet Hulk body used to create The Maxx</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>Planet Hulk body use to create The Maxx</td>\n",
       "      <td>planet hulk body use create maxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comicbooks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_112uoc</td>\n",
       "      <td>[OC] Frontier Graveyard has a new episode.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>11inhqq</td>\n",
       "      <td>profesone</td>\n",
       "      <td>0</td>\n",
       "      <td>1677990582</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-03-05 04:29:42</td>\n",
       "      <td>[OC] Frontier Graveyard has a new episode.</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>[OC] Frontier Graveyard have a new episode.</td>\n",
       "      <td>oc frontier graveyard new episode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comicbooks</td>\n",
       "      <td>Starting my second box and would prefer not ge...</td>\n",
       "      <td>t2_68d44nnp</td>\n",
       "      <td>Any recommendations on quality storage boxes?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>self.comicbooks</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>11inb9l</td>\n",
       "      <td>HenjaminBenry</td>\n",
       "      <td>0</td>\n",
       "      <td>1677990047</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-03-05 04:20:47</td>\n",
       "      <td>Any recommendations on quality storage boxes? ...</td>\n",
       "      <td>200</td>\n",
       "      <td>33</td>\n",
       "      <td>Any recommendation on quality storage boxes? S...</td>\n",
       "      <td>recommendation quality storage boxes starting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comicbooks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_j0ubh1u</td>\n",
       "      <td>Favorite comic book cameos from characters out...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>11ilad6</td>\n",
       "      <td>Christianduty</td>\n",
       "      <td>0</td>\n",
       "      <td>1677984253</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-03-05 02:44:13</td>\n",
       "      <td>Favorite comic book cameos from characters out...</td>\n",
       "      <td>61</td>\n",
       "      <td>9</td>\n",
       "      <td>Favorite comic book cameo from character outsi...</td>\n",
       "      <td>favorite comic book cameo character outside co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comicbooks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_75sge4r3</td>\n",
       "      <td>Got these Two off of Amazon today</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>11il46k</td>\n",
       "      <td>NinjaZero2099</td>\n",
       "      <td>0</td>\n",
       "      <td>1677983771</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-03-05 02:36:11</td>\n",
       "      <td>Got these Two off of Amazon today</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>Got these Two off of Amazon today</td>\n",
       "      <td>got two amazon today</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit                                           selftext  \\\n",
       "0  comicbooks                                                NaN   \n",
       "1  comicbooks                                                NaN   \n",
       "2  comicbooks  Starting my second box and would prefer not ge...   \n",
       "3  comicbooks                                                NaN   \n",
       "4  comicbooks                                                NaN   \n",
       "\n",
       "  author_fullname                                              title  \\\n",
       "0     t2_a0obk3gv           Planet Hulk body used to create The Maxx   \n",
       "1       t2_112uoc         [OC] Frontier Graveyard has a new episode.   \n",
       "2     t2_68d44nnp      Any recommendations on quality storage boxes?   \n",
       "3      t2_j0ubh1u  Favorite comic book cameos from characters out...   \n",
       "4     t2_75sge4r3                  Got these Two off of Amazon today   \n",
       "\n",
       "   upvote_ratio  is_reddit_media_domain           domain  over_18  spoiler  \\\n",
       "0           1.0                   False       reddit.com    False    False   \n",
       "1           1.0                    True        i.redd.it    False    False   \n",
       "2           1.0                   False  self.comicbooks    False    False   \n",
       "3           1.0                   False       reddit.com    False    False   \n",
       "4           1.0                    True        i.redd.it    False    False   \n",
       "\n",
       "        id         author  num_comments  created_utc  is_video  \\\n",
       "0  11inl15   Hairy-Ad9897             0   1677990850     False   \n",
       "1  11inhqq      profesone             0   1677990582     False   \n",
       "2  11inb9l  HenjaminBenry             0   1677990047     False   \n",
       "3  11ilad6  Christianduty             0   1677984253     False   \n",
       "4  11il46k  NinjaZero2099             0   1677983771     False   \n",
       "\n",
       "     created_datetime                                      combined_text  \\\n",
       "0 2023-03-05 04:34:10           Planet Hulk body used to create The Maxx   \n",
       "1 2023-03-05 04:29:42         [OC] Frontier Graveyard has a new episode.   \n",
       "2 2023-03-05 04:20:47  Any recommendations on quality storage boxes? ...   \n",
       "3 2023-03-05 02:44:13  Favorite comic book cameos from characters out...   \n",
       "4 2023-03-05 02:36:11                  Got these Two off of Amazon today   \n",
       "\n",
       "   combined_text_length  combined_wordcount  \\\n",
       "0                    40                   8   \n",
       "1                    42                   7   \n",
       "2                   200                  33   \n",
       "3                    61                   9   \n",
       "4                    33                   7   \n",
       "\n",
       "                                     lemmatized_text  \\\n",
       "0            Planet Hulk body use to create The Maxx   \n",
       "1        [OC] Frontier Graveyard have a new episode.   \n",
       "2  Any recommendation on quality storage boxes? S...   \n",
       "3  Favorite comic book cameo from character outsi...   \n",
       "4                  Got these Two off of Amazon today   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0                   planet hulk body use create maxx  \n",
       "1                  oc frontier graveyard new episode  \n",
       "2  recommendation quality storage boxes starting ...  \n",
       "3  favorite comic book cameo character outside co...  \n",
       "4                               got two amazon today  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2654cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4845, 20)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e59ea8",
   "metadata": {},
   "source": [
    "# Write output to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c88c735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'./data/{target_subreddit}_{scrape_type}s_preprocessed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
