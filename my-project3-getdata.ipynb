{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e6a6e44",
   "metadata": {},
   "source": [
    "# Gathering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e624057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDIT ME to change target subreddit...\n",
    "# target_subreddit_list = ['Naruto', 'BokuNoHeroAcademia', 'anime', 'manga', 'comicbooks', 'StarWars', 'startrek']\n",
    "# target_subreddit_list = ['LonghornNation', 'cfb', 'Genshin_Impact']\n",
    "target_subreddit_list = ['comicbooks']\n",
    "target_num_posts = 5000\n",
    "scrape_type = \"submission\"  # set to \"submission\" or \"comment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebbbdf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import requests\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5121d0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://api.pushshift.io/reddit/search/{scrape_type}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c779f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_get_data(subreddit, num_posts):\n",
    "    joined_df = pd.DataFrame()\n",
    "    \n",
    "    my_changing_utc = None #1677703953\n",
    "    \n",
    "    max_num_posts = 500\n",
    "    remaining_num = num_posts\n",
    "       \n",
    "    i = 0\n",
    "    while i < num_posts:\n",
    "        \n",
    "        if remaining_num < max_num_posts:\n",
    "            temp_size = remaining_num\n",
    "        else:\n",
    "            temp_size = max_num_posts\n",
    "            remaining_num -= temp_size\n",
    "        \n",
    "        params = {\n",
    "            'subreddit': subreddit,\n",
    "            'size':temp_size,\n",
    "            'before': my_changing_utc\n",
    "        }\n",
    "\n",
    "        breakflag = False\n",
    "        res = requests.get(url, params)\n",
    "        if res.status_code < 400:\n",
    "            data = res.json()\n",
    "            posts = data['data']\n",
    "            df = pd.DataFrame(posts)\n",
    "        else:\n",
    "            print(f\"CAUTION: During requests.get, received code: {res.status_code}\")\n",
    "            breakflag = True\n",
    "            break\n",
    "        \n",
    "        if breakflag == False:\n",
    "            if i == 0:\n",
    "                joined_df = df\n",
    "            else:\n",
    "                joined_df = pd.concat([joined_df, df], axis=0)\n",
    "            i += temp_size\n",
    "\n",
    "        my_changing_utc = df['created_utc'].min()  # .min() suggestion from Kate Skibo\n",
    "\n",
    "        \n",
    "    \n",
    "    temp = joined_df[joined_df['subreddit'].str.lower() == subreddit.lower()] #drop entries with errant subreddit\n",
    "    \n",
    "    if scrape_type == \"submission\":\n",
    "        joined_df = temp.drop_duplicates(subset='title')            #drop_duplicates idea from Jack Vaughan\n",
    "    elif scrape_type == \"comment\":\n",
    "        joined_df = temp.drop_duplicates(subset=['author','body'])  #drop_duplicates criteria from Jack Vaughan\n",
    "    \n",
    "    return joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fe6cff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4845 posts scraped from r/comicbooks\n"
     ]
    }
   ],
   "source": [
    "for target_subreddit in target_subreddit_list:\n",
    "    joined_df = my_get_data(target_subreddit, target_num_posts)\n",
    "    joined_df.to_csv(f'./data/{target_subreddit}_{scrape_type}s.csv')\n",
    "    print(f\"{joined_df.shape[0]} posts scraped from r/{target_subreddit}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
